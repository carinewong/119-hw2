	Given the pipeline, we would anticipate for latency to generally remain stable and throughput to increase with larger data. For our pipelines, the actions specific to each problem vary, but we are in general conducting simple operations like mapping to a key and value pair, reducing and counting up quantities, and outputting those values. In this process, we’d expect latency to remain generally stable because it still takes the same steps and thus same time for one particular item to make it through the pipeline. Throughput would rise: throughput is low when our data is small because of the overhead costs of scheduling things such as arranging for map and reduce to execute when we call .collect(). With higher N, our pipeline benefits from the data partitioning and is able to send more items through the pipeline per one unit of time than for a smaller data set. When parallelism is doubled, latency wouldn’t change significantly for us as it still takes the same amount of work and steps per item to make it through the pipeline. Throughput, in a perfect scenario, might double: twice as many things are running in tandem, enabling doubling. However, based on Amdahl’s law, speedup is bounded by the function (1/1-p), illustrating that speedup is capped off at how much is actually parallelizable of our pipeline. Not everything is parallelizable, such as the overhead and the partitioning of all the data into their groups. More data would take longer for this overhead step for example, and thus we in practice may not necessarily reach that speedup.
	In practice, our expectation is somewhat matched with question 1: Latency is mostly consistent across different N data size and P partition count parameters, indicating that it takes just as long for one item to make it through the pipeline between the various configurations. However, pipelines where N = 1,000,000 have substantially higher latency, and I hypothesize that this change is affected by the fact that a data set of that size for my Codespace’s configuration is high and has substantially higher overhead for partitioning and other steps. Throughput increases for higher N and P, which matches expectations; larger data benefits from scaling, and thus has higher throughput. Smaller partition numbers have slightly smaller throughput, which also matches expectations as not as much data can make it through if we only have a small number of data going through at one time. We expected throughput to actually double from one partition size to another, but throughput from P to P remains approximately the same. For example, at both 8 and 16 Partitions, throughput is ~ 40,000k. In this case, it looks like parallelism has minimal effect on throughput, while the size of the data has drastic influence. This doesn’t quite match our expectations, potentially implying that the steps in our pipeline don’t particularly benefit from parallelism but throughput still benefits from scale (at least up to 1,000,000, our largest N size). Our expectations would have been that throughput for 16 Partitions, relative to the throughput for 8k partitions, would be less than 80k and greater than 40k items per second. Other expected throughputs would follow the same doubling pattern.
	I conjecture that the amount of overhead that our pipeline has and the amount of code that is parallelizable makes our pipeline’s throughput not change substantially between different numbers of partitions, but increase greatly with increased N; latency as anticipated remains relatively the same for different inputs for our P and N arguments because one item will take the same amount of steps as a non-parallelized pipeline make it through all of the steps in our MapReduce. Our helper function for anglicizing more and potentially larger numbers takes substantial time to iterate through, which is another overhead that may not benefit as substantially from parallelization. Another overhead cost that affects my pipeline is the fact that I have to connect to a Github Codespace, which runs the code on a server. That connection time may also affect my pipeline’s throughput relative to parallelism. The amount of data affects the amount of throughput our pipeline gets. Our pipeline thus still benefits from scale: the server and computer is optimized to handle large volumes of data, and overheads are maybe reduced for large data going through the same pipeline. Latency matches our expectations (consistent across all the different configurations) besides our largest N size, which may match expectations because there may be substantial overhead (such as putting data in partitions), thus causing one item to take longer to make it through the pipeline. Overall, our application doesn’t quite match our expectations for throughput, but roughly aligns with expectations for pipeline latency.
